{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea604d79-deef-4285-a866-88cc52d3a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0527bb18-fad7-4de7-8956-af9c3cc9c130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>tenure_group_13 - 24</th>\n",
       "      <th>tenure_group_25 - 36</th>\n",
       "      <th>tenure_group_37 - 48</th>\n",
       "      <th>tenure_group_49 - 60</th>\n",
       "      <th>tenure_group_61 - 72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gender  SeniorCitizen  Partner  Dependents  PhoneService  \\\n",
       "0           0       1              0        1           0             0   \n",
       "1           1       0              0        0           0             1   \n",
       "2           2       0              0        0           0             1   \n",
       "3           3       0              0        0           0             0   \n",
       "4           4       1              0        0           0             1   \n",
       "\n",
       "   PaperlessBilling  MonthlyCharges  TotalCharges  Churn  ...  \\\n",
       "0                 1           29.85         29.85      0  ...   \n",
       "1                 0           56.95       1889.50      0  ...   \n",
       "2                 1           53.85        108.15      1  ...   \n",
       "3                 0           42.30       1840.75      0  ...   \n",
       "4                 1           70.70        151.65      1  ...   \n",
       "\n",
       "   Contract_One year  Contract_Two year  \\\n",
       "0                0.0                0.0   \n",
       "1                1.0                0.0   \n",
       "2                0.0                0.0   \n",
       "3                1.0                0.0   \n",
       "4                0.0                0.0   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                    0.0                             1.0   \n",
       "1                                    0.0                             0.0   \n",
       "2                                    0.0                             0.0   \n",
       "3                                    0.0                             0.0   \n",
       "4                                    0.0                             1.0   \n",
       "\n",
       "   PaymentMethod_Mailed check  tenure_group_13 - 24   tenure_group_25 - 36   \\\n",
       "0                         0.0                    0.0                    0.0   \n",
       "1                         1.0                    0.0                    1.0   \n",
       "2                         1.0                    0.0                    0.0   \n",
       "3                         0.0                    0.0                    0.0   \n",
       "4                         0.0                    0.0                    0.0   \n",
       "\n",
       "   tenure_group_37 - 48   tenure_group_49 - 60   tenure_group_61 - 72   \n",
       "0                    0.0                    0.0                    0.0  \n",
       "1                    0.0                    0.0                    0.0  \n",
       "2                    0.0                    0.0                    0.0  \n",
       "3                    1.0                    0.0                    0.0  \n",
       "4                    0.0                    0.0                    0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tel_churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abebd24-4b01-4a70-8692-5bc870be660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8e94cc-04c7-47e2-883e-608218b4b435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>MultipleLines_No phone service</th>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "      <th>tenure_group_13 - 24</th>\n",
       "      <th>tenure_group_25 - 36</th>\n",
       "      <th>tenure_group_37 - 48</th>\n",
       "      <th>tenure_group_49 - 60</th>\n",
       "      <th>tenure_group_61 - 72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.80</td>\n",
       "      <td>1990.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7028</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103.20</td>\n",
       "      <td>7362.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7029</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.60</td>\n",
       "      <td>346.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74.40</td>\n",
       "      <td>306.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105.65</td>\n",
       "      <td>6844.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7032 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen  Partner  Dependents  PhoneService  \\\n",
       "0          1              0        1           0             0   \n",
       "1          0              0        0           0             1   \n",
       "2          0              0        0           0             1   \n",
       "3          0              0        0           0             0   \n",
       "4          1              0        0           0             1   \n",
       "...      ...            ...      ...         ...           ...   \n",
       "7027       0              0        1           1             1   \n",
       "7028       1              0        1           1             1   \n",
       "7029       1              0        1           1             0   \n",
       "7030       0              1        1           0             1   \n",
       "7031       0              0        0           0             1   \n",
       "\n",
       "      PaperlessBilling  MonthlyCharges  TotalCharges  \\\n",
       "0                    1           29.85         29.85   \n",
       "1                    0           56.95       1889.50   \n",
       "2                    1           53.85        108.15   \n",
       "3                    0           42.30       1840.75   \n",
       "4                    1           70.70        151.65   \n",
       "...                ...             ...           ...   \n",
       "7027                 1           84.80       1990.50   \n",
       "7028                 1          103.20       7362.90   \n",
       "7029                 1           29.60        346.45   \n",
       "7030                 1           74.40        306.60   \n",
       "7031                 1          105.65       6844.50   \n",
       "\n",
       "      MultipleLines_No phone service  MultipleLines_Yes  ...  \\\n",
       "0                                1.0                0.0  ...   \n",
       "1                                0.0                0.0  ...   \n",
       "2                                0.0                0.0  ...   \n",
       "3                                1.0                0.0  ...   \n",
       "4                                0.0                0.0  ...   \n",
       "...                              ...                ...  ...   \n",
       "7027                             0.0                1.0  ...   \n",
       "7028                             0.0                1.0  ...   \n",
       "7029                             1.0                0.0  ...   \n",
       "7030                             0.0                1.0  ...   \n",
       "7031                             0.0                0.0  ...   \n",
       "\n",
       "      Contract_One year  Contract_Two year  \\\n",
       "0                   0.0                0.0   \n",
       "1                   1.0                0.0   \n",
       "2                   0.0                0.0   \n",
       "3                   1.0                0.0   \n",
       "4                   0.0                0.0   \n",
       "...                 ...                ...   \n",
       "7027                1.0                0.0   \n",
       "7028                1.0                0.0   \n",
       "7029                0.0                0.0   \n",
       "7030                0.0                0.0   \n",
       "7031                0.0                1.0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                       0.0                             1.0   \n",
       "1                                       0.0                             0.0   \n",
       "2                                       0.0                             0.0   \n",
       "3                                       0.0                             0.0   \n",
       "4                                       0.0                             1.0   \n",
       "...                                     ...                             ...   \n",
       "7027                                    0.0                             0.0   \n",
       "7028                                    1.0                             0.0   \n",
       "7029                                    0.0                             1.0   \n",
       "7030                                    0.0                             0.0   \n",
       "7031                                    0.0                             0.0   \n",
       "\n",
       "      PaymentMethod_Mailed check  tenure_group_13 - 24   \\\n",
       "0                            0.0                    0.0   \n",
       "1                            1.0                    0.0   \n",
       "2                            1.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            0.0                    0.0   \n",
       "...                          ...                    ...   \n",
       "7027                         1.0                    1.0   \n",
       "7028                         0.0                    0.0   \n",
       "7029                         0.0                    0.0   \n",
       "7030                         1.0                    0.0   \n",
       "7031                         0.0                    0.0   \n",
       "\n",
       "      tenure_group_25 - 36   tenure_group_37 - 48   tenure_group_49 - 60   \\\n",
       "0                       0.0                    0.0                    0.0   \n",
       "1                       1.0                    0.0                    0.0   \n",
       "2                       0.0                    0.0                    0.0   \n",
       "3                       0.0                    1.0                    0.0   \n",
       "4                       0.0                    0.0                    0.0   \n",
       "...                     ...                    ...                    ...   \n",
       "7027                    0.0                    0.0                    0.0   \n",
       "7028                    0.0                    0.0                    0.0   \n",
       "7029                    0.0                    0.0                    0.0   \n",
       "7030                    0.0                    0.0                    0.0   \n",
       "7031                    0.0                    0.0                    0.0   \n",
       "\n",
       "      tenure_group_61 - 72   \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "...                     ...  \n",
       "7027                    0.0  \n",
       "7028                    1.0  \n",
       "7029                    0.0  \n",
       "7030                    0.0  \n",
       "7031                    1.0  \n",
       "\n",
       "[7032 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop('Churn',axis=1)\n",
    "y=df['Churn']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "456b921d-47cb-4afb-81f5-5719883d30e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "7027    0\n",
       "7028    0\n",
       "7029    0\n",
       "7030    1\n",
       "7031    0\n",
       "Name: Churn, Length: 7032, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbbdd0f-2e91-4de7-9d95-3785c30fdf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ceb2a0-cf4f-4eb7-adee-7dbdc147735c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00943013, -0.44032709,  1.03561683, ..., -0.34861311,\n",
       "        -0.36632438, -0.50013332],\n",
       "       [-0.99065797, -0.44032709, -0.9656081 , ..., -0.34861311,\n",
       "        -0.36632438, -0.50013332],\n",
       "       [-0.99065797, -0.44032709, -0.9656081 , ..., -0.34861311,\n",
       "        -0.36632438, -0.50013332],\n",
       "       ...,\n",
       "       [ 1.00943013, -0.44032709,  1.03561683, ..., -0.34861311,\n",
       "        -0.36632438, -0.50013332],\n",
       "       [-0.99065797,  2.27103902,  1.03561683, ..., -0.34861311,\n",
       "        -0.36632438, -0.50013332],\n",
       "       [-0.99065797, -0.44032709, -0.9656081 , ..., -0.34861311,\n",
       "        -0.36632438,  1.99946688]], shape=(7032, 34))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "997df139-873c-492d-9286-6e0df84d4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d1cda4d-ef09-4668-a4f0-305da2e23e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 17:51:11,065] A new study created in memory with name: no-name-8e84595e-9a7f-4316-8e49-1b667c2b2193\n",
      "[I 2025-06-25 17:51:20,586] Trial 0 finished with value: 0.5757006895488255 and parameters: {'n_estimators': 365, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.5757006895488255.\n",
      "[I 2025-06-25 17:51:35,684] Trial 1 finished with value: 0.579863829255661 and parameters: {'n_estimators': 458, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 1 with value: 0.579863829255661.\n",
      "[I 2025-06-25 17:51:46,514] Trial 2 finished with value: 0.5785957248839424 and parameters: {'n_estimators': 352, 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 1 with value: 0.579863829255661.\n",
      "[I 2025-06-25 17:51:54,347] Trial 3 finished with value: 0.5795116858672232 and parameters: {'n_estimators': 245, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 1 with value: 0.579863829255661.\n",
      "[I 2025-06-25 17:51:59,591] Trial 4 finished with value: 0.5798549847073703 and parameters: {'n_estimators': 158, 'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.579863829255661.\n",
      "[I 2025-06-25 17:52:11,118] Trial 5 finished with value: 0.5775271568771878 and parameters: {'n_estimators': 325, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 1 with value: 0.579863829255661.\n",
      "[I 2025-06-25 17:52:26,326] Trial 6 finished with value: 0.5843950301204506 and parameters: {'n_estimators': 496, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:52:33,334] Trial 7 finished with value: 0.5814718195967168 and parameters: {'n_estimators': 240, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:52:43,493] Trial 8 finished with value: 0.5776017778051223 and parameters: {'n_estimators': 334, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:52:46,640] Trial 9 finished with value: 0.5720356749047371 and parameters: {'n_estimators': 111, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:52:55,536] Trial 10 finished with value: 0.23634582443785107 and parameters: {'n_estimators': 500, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:53:03,199] Trial 11 finished with value: 0.5821553351413812 and parameters: {'n_estimators': 240, 'max_depth': 9, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:53:09,338] Trial 12 finished with value: 0.5447439179364872 and parameters: {'n_estimators': 229, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:53:22,550] Trial 13 finished with value: 0.5840018100980645 and parameters: {'n_estimators': 426, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:53:35,093] Trial 14 finished with value: 0.581605887373384 and parameters: {'n_estimators': 424, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:53:41,974] Trial 15 finished with value: 0.2352500974476376 and parameters: {'n_estimators': 409, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:53:57,065] Trial 16 finished with value: 0.5773552351435838 and parameters: {'n_estimators': 472, 'max_depth': 21, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:54:08,870] Trial 17 finished with value: 0.5841203249760557 and parameters: {'n_estimators': 405, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:54:17,664] Trial 18 finished with value: 0.5429911648951119 and parameters: {'n_estimators': 391, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:54:32,091] Trial 19 finished with value: 0.5778661598895345 and parameters: {'n_estimators': 497, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:54:41,044] Trial 20 finished with value: 0.5794843462712562 and parameters: {'n_estimators': 292, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 6 with value: 0.5843950301204506.\n",
      "[I 2025-06-25 17:54:55,472] Trial 21 finished with value: 0.5845036794225782 and parameters: {'n_estimators': 446, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 21 with value: 0.5845036794225782.\n",
      "[I 2025-06-25 17:55:11,644] Trial 22 finished with value: 0.5798593485227242 and parameters: {'n_estimators': 473, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 21 with value: 0.5845036794225782.\n",
      "[I 2025-06-25 17:55:25,929] Trial 23 finished with value: 0.5800849359537477 and parameters: {'n_estimators': 437, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 21 with value: 0.5845036794225782.\n",
      "[I 2025-06-25 17:55:34,548] Trial 24 finished with value: 0.5417383107322635 and parameters: {'n_estimators': 388, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 21 with value: 0.5845036794225782.\n",
      "[I 2025-06-25 17:55:48,503] Trial 25 finished with value: 0.587768519907656 and parameters: {'n_estimators': 451, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:56:00,106] Trial 26 finished with value: 0.5750208818118281 and parameters: {'n_estimators': 451, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:56:15,694] Trial 27 finished with value: 0.5787528419423589 and parameters: {'n_estimators': 477, 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:56:26,646] Trial 28 finished with value: 0.5781327201472803 and parameters: {'n_estimators': 278, 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:56:35,822] Trial 29 finished with value: 0.5629137864356977 and parameters: {'n_estimators': 362, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:56:46,421] Trial 30 finished with value: 0.5823085070130988 and parameters: {'n_estimators': 378, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:56:58,661] Trial 31 finished with value: 0.5837992189424156 and parameters: {'n_estimators': 413, 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:57:12,128] Trial 32 finished with value: 0.5827490051410473 and parameters: {'n_estimators': 453, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:57:23,915] Trial 33 finished with value: 0.5804535069698662 and parameters: {'n_estimators': 439, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:57:39,222] Trial 34 finished with value: 0.580488495294201 and parameters: {'n_estimators': 498, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:57:50,656] Trial 35 finished with value: 0.578189559079197 and parameters: {'n_estimators': 398, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:58:07,325] Trial 36 finished with value: 0.5807197623850914 and parameters: {'n_estimators': 466, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:58:17,191] Trial 37 finished with value: 0.5738794307018977 and parameters: {'n_estimators': 347, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:58:26,174] Trial 38 finished with value: 0.5856419491453778 and parameters: {'n_estimators': 447, 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:58:31,788] Trial 39 finished with value: 0.41146621516939214 and parameters: {'n_estimators': 451, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:58:47,428] Trial 40 finished with value: 0.5836510552264171 and parameters: {'n_estimators': 481, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:59:02,279] Trial 41 finished with value: 0.5818521429674656 and parameters: {'n_estimators': 433, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:59:17,836] Trial 42 finished with value: 0.5854189720265974 and parameters: {'n_estimators': 410, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:59:29,406] Trial 43 finished with value: 0.5835505273502706 and parameters: {'n_estimators': 315, 'max_depth': 15, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 17:59:46,620] Trial 44 finished with value: 0.5860925163547444 and parameters: {'n_estimators': 458, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 18:00:00,721] Trial 45 finished with value: 0.5805960168407094 and parameters: {'n_estimators': 374, 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 18:00:07,437] Trial 46 finished with value: 0.5783844542520173 and parameters: {'n_estimators': 183, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 18:00:22,379] Trial 47 finished with value: 0.5803526125863306 and parameters: {'n_estimators': 424, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 18:00:39,257] Trial 48 finished with value: 0.586859944201424 and parameters: {'n_estimators': 451, 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 25 with value: 0.587768519907656.\n",
      "[I 2025-06-25 18:00:55,952] Trial 49 finished with value: 0.5844027878811765 and parameters: {'n_estimators': 461, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 25 with value: 0.587768519907656.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Parameters {'n_estimators': 451, 'max_depth': 12, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "#random forest classifier\n",
    "def objective_rf(trial):\n",
    "    params={\n",
    "        'n_estimators':trial.suggest_int('n_estimators',100,500),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,30),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,10),\n",
    "        'min_samples_leaf':trial.suggest_int('min_samples_leaf',1,10),\n",
    "        'max_features':trial.suggest_categorical('max_features',['log2','sqrt'])\n",
    "    }\n",
    "\n",
    "    model=RandomForestClassifier(**params,random_state=42)\n",
    "    return cross_val_score(model,X_train,y_train,cv=5,scoring='f1').mean()\n",
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf,n_trials=50)\n",
    "print(\"Random Forest Best Parameters\",study_rf.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b07b6546-3d63-4d1b-b972-145dde8ec1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1033\n",
      "           1       0.66      0.48      0.55       374\n",
      "\n",
      "    accuracy                           0.80      1407\n",
      "   macro avg       0.74      0.69      0.71      1407\n",
      "weighted avg       0.78      0.80      0.78      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_rf = RandomForestClassifier(**study_rf.best_params)\n",
    "best_model_rf.fit(X_train,y_train)\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_rf,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "017aa333-af40-4f6e-bb68-0e8a8e4e46e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 18:05:34,648] A new study created in memory with name: no-name-519191f3-3fff-4844-ab5e-8414937bb1f4\n",
      "[I 2025-06-25 18:05:34,901] Trial 0 finished with value: 0.5410052675875461 and parameters: {'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 17, 'criterion': 'entropy'}. Best is trial 0 with value: 0.5410052675875461.\n",
      "[I 2025-06-25 18:05:35,119] Trial 1 finished with value: 0.53432355141371 and parameters: {'max_depth': 16, 'min_samples_split': 18, 'min_samples_leaf': 4, 'criterion': 'gini'}. Best is trial 0 with value: 0.5410052675875461.\n",
      "[I 2025-06-25 18:05:35,350] Trial 2 finished with value: 0.5579017430400984 and parameters: {'max_depth': 11, 'min_samples_split': 11, 'min_samples_leaf': 2, 'criterion': 'entropy'}. Best is trial 2 with value: 0.5579017430400984.\n",
      "[I 2025-06-25 18:05:35,579] Trial 3 finished with value: 0.5051494349467494 and parameters: {'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'gini'}. Best is trial 2 with value: 0.5579017430400984.\n",
      "[I 2025-06-25 18:05:35,783] Trial 4 finished with value: 0.6176118652644291 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 16, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:36,025] Trial 5 finished with value: 0.5165585891262838 and parameters: {'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 8, 'criterion': 'gini'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:36,271] Trial 6 finished with value: 0.5158894558100082 and parameters: {'max_depth': 28, 'min_samples_split': 9, 'min_samples_leaf': 8, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:36,475] Trial 7 finished with value: 0.5770962920752604 and parameters: {'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 18, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:36,640] Trial 8 finished with value: 0.5842566934656336 and parameters: {'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 5, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:36,875] Trial 9 finished with value: 0.541927005764852 and parameters: {'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 14, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:37,008] Trial 10 finished with value: 0.5545578502493601 and parameters: {'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 13, 'criterion': 'gini'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:37,138] Trial 11 finished with value: 0.0 and parameters: {'max_depth': 2, 'min_samples_split': 20, 'min_samples_leaf': 20, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:37,352] Trial 12 finished with value: 0.6101691811696481 and parameters: {'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 10, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:37,595] Trial 13 finished with value: 0.5761635707797248 and parameters: {'max_depth': 9, 'min_samples_split': 14, 'min_samples_leaf': 12, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:37,842] Trial 14 finished with value: 0.5567165627949031 and parameters: {'max_depth': 12, 'min_samples_split': 14, 'min_samples_leaf': 9, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:38,027] Trial 15 finished with value: 0.6052119965977811 and parameters: {'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 15, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:38,274] Trial 16 finished with value: 0.5464942666329544 and parameters: {'max_depth': 15, 'min_samples_split': 11, 'min_samples_leaf': 11, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:38,486] Trial 17 finished with value: 0.6095482557536589 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 16, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:38,690] Trial 18 finished with value: 0.5468336682680727 and parameters: {'max_depth': 20, 'min_samples_split': 17, 'min_samples_leaf': 20, 'criterion': 'gini'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:38,946] Trial 19 finished with value: 0.546387557636933 and parameters: {'max_depth': 14, 'min_samples_split': 15, 'min_samples_leaf': 9, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:39,114] Trial 20 finished with value: 0.48730516794835854 and parameters: {'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 6, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:39,339] Trial 21 finished with value: 0.6095482557536589 and parameters: {'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 16, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:39,591] Trial 22 finished with value: 0.5638024463518893 and parameters: {'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 18, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:39,862] Trial 23 finished with value: 0.5631527508833172 and parameters: {'max_depth': 11, 'min_samples_split': 20, 'min_samples_leaf': 14, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:40,009] Trial 24 finished with value: 0.0 and parameters: {'max_depth': 2, 'min_samples_split': 13, 'min_samples_leaf': 11, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:40,218] Trial 25 finished with value: 0.5850815167177938 and parameters: {'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 16, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:40,469] Trial 26 finished with value: 0.5514190259809304 and parameters: {'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 12, 'criterion': 'gini'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:40,681] Trial 27 finished with value: 0.5770962920752604 and parameters: {'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 18, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:40,934] Trial 28 finished with value: 0.541927005764852 and parameters: {'max_depth': 18, 'min_samples_split': 16, 'min_samples_leaf': 14, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:41,139] Trial 29 finished with value: 0.6095482557536589 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 16, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:41,412] Trial 30 finished with value: 0.5529165053054674 and parameters: {'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 10, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:41,638] Trial 31 finished with value: 0.6095482557536589 and parameters: {'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 16, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:41,809] Trial 32 finished with value: 0.48730516794835854 and parameters: {'max_depth': 4, 'min_samples_split': 12, 'min_samples_leaf': 17, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:42,023] Trial 33 finished with value: 0.6048387669569232 and parameters: {'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 19, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:42,240] Trial 34 finished with value: 0.5648470612662189 and parameters: {'max_depth': 10, 'min_samples_split': 11, 'min_samples_leaf': 15, 'criterion': 'gini'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:42,444] Trial 35 finished with value: 0.584066319502311 and parameters: {'max_depth': 5, 'min_samples_split': 15, 'min_samples_leaf': 2, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:42,694] Trial 36 finished with value: 0.5586786784914596 and parameters: {'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 13, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:42,923] Trial 37 finished with value: 0.5193262662824465 and parameters: {'max_depth': 23, 'min_samples_split': 12, 'min_samples_leaf': 7, 'criterion': 'gini'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:43,138] Trial 38 finished with value: 0.5613371871520252 and parameters: {'max_depth': 8, 'min_samples_split': 15, 'min_samples_leaf': 17, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:43,407] Trial 39 finished with value: 0.6052119965977811 and parameters: {'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 15, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:43,631] Trial 40 finished with value: 0.5528063964355929 and parameters: {'max_depth': 30, 'min_samples_split': 17, 'min_samples_leaf': 13, 'criterion': 'gini'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:43,829] Trial 41 finished with value: 0.6095482557536589 and parameters: {'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 16, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:44,075] Trial 42 finished with value: 0.5748537491226238 and parameters: {'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 19, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:44,278] Trial 43 finished with value: 0.6176118652644291 and parameters: {'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 17, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:44,434] Trial 44 finished with value: 0.5880294424063892 and parameters: {'max_depth': 3, 'min_samples_split': 8, 'min_samples_leaf': 17, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:44,606] Trial 45 finished with value: 0.48730516794835854 and parameters: {'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 19, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:44,827] Trial 46 finished with value: 0.5761635707797248 and parameters: {'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 12, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:45,027] Trial 47 finished with value: 0.6054125056622454 and parameters: {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 10, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:45,160] Trial 48 finished with value: 0.0 and parameters: {'max_depth': 2, 'min_samples_split': 12, 'min_samples_leaf': 14, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n",
      "[I 2025-06-25 18:05:45,411] Trial 49 finished with value: 0.5501822050842933 and parameters: {'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 8, 'criterion': 'entropy'}. Best is trial 4 with value: 0.6176118652644291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Best Parameters {'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 16, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "#Decision tree Classifier\n",
    "def objective_dt(trial):\n",
    "    params={\n",
    "        'max_depth':trial.suggest_int('max_depth',2,30),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,20),\n",
    "        'min_samples_leaf':trial.suggest_int('min_samples_leaf',1,20),\n",
    "        'criterion':trial.suggest_categorical('criterion',['gini','entropy'])\n",
    "    }\n",
    "    \n",
    "    model=DecisionTreeClassifier(**params,random_state=42)\n",
    "    return cross_val_score(model,X_train,y_train,cv=5,scoring='f1').mean()\n",
    "\n",
    "study_dt = optuna.create_study(direction='maximize')\n",
    "study_dt.optimize(objective_dt,n_trials=50)\n",
    "print(\"Decision Tree Best Parameters\",study_dt.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3df2ec9d-2725-4cc9-a1c5-40c40e8013eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83      1033\n",
      "           1       0.55      0.61      0.58       374\n",
      "\n",
      "    accuracy                           0.76      1407\n",
      "   macro avg       0.70      0.71      0.70      1407\n",
      "weighted avg       0.77      0.76      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_dt = DecisionTreeClassifier(**study_dt.best_params)\n",
    "best_model_dt.fit(X_train,y_train)\n",
    "y_pred_dt = best_model_dt.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_dt,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec554faa-180f-4beb-bc75-a5015e11134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 18:06:18,827] A new study created in memory with name: no-name-4581ad02-dfc1-4600-a73d-5d4dc11da44e\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:19,160] Trial 0 finished with value: 0.537305697241887 and parameters: {'C': 0.012544884168675758, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 0 with value: 0.537305697241887.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:21,240] Trial 1 finished with value: 0.505460167381797 and parameters: {'C': 0.010484418601738467, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 0 with value: 0.537305697241887.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:21,424] Trial 2 finished with value: 0.560173458756101 and parameters: {'C': 0.0032497666523324544, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 2 with value: 0.560173458756101.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:23,030] Trial 3 finished with value: 0.5064525385510547 and parameters: {'C': 0.16661218853281612, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 2 with value: 0.560173458756101.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:25,220] Trial 4 finished with value: 0.5064525385510547 and parameters: {'C': 2.5490760147585068, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 2 with value: 0.560173458756101.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:25,473] Trial 5 finished with value: 0.5864564188190703 and parameters: {'C': 4.295135953594984, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 5 with value: 0.5864564188190703.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:27,560] Trial 6 finished with value: 0.5034763587544437 and parameters: {'C': 0.0065118873094557475, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 5 with value: 0.5864564188190703.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:27,677] Trial 7 finished with value: 0.5045172671750078 and parameters: {'C': 0.0036715386458184606, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 5 with value: 0.5864564188190703.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:29,394] Trial 8 finished with value: 0.5064525385510547 and parameters: {'C': 0.00042721505206921455, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 5 with value: 0.5864564188190703.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:31,579] Trial 9 finished with value: 0.5064525385510547 and parameters: {'C': 0.5720504023111873, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 5 with value: 0.5864564188190703.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:31,792] Trial 10 finished with value: 0.5883029878225787 and parameters: {'C': 9.914873933999306, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.5883029878225787.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:32,028] Trial 11 finished with value: 0.5862290303506184 and parameters: {'C': 9.917394010976704, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.5883029878225787.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:32,233] Trial 12 finished with value: 0.58792858339663 and parameters: {'C': 8.384627919428175, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.5883029878225787.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:32,462] Trial 13 finished with value: 0.5865854278467214 and parameters: {'C': 0.44077185562049664, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.5883029878225787.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:32,684] Trial 14 finished with value: 0.5869872884381655 and parameters: {'C': 0.10929860455627959, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 10 with value: 0.5883029878225787.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:32,890] Trial 15 finished with value: 0.5889897940669133 and parameters: {'C': 2.6179180695948627, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:33,118] Trial 16 finished with value: 0.5864036636945233 and parameters: {'C': 1.1826982388914173, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:33,352] Trial 17 finished with value: 0.5869777996108991 and parameters: {'C': 1.6076684437699673, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:33,572] Trial 18 finished with value: 0.5868620934801989 and parameters: {'C': 0.06690680568341889, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:33,739] Trial 19 finished with value: 0.5420264731497395 and parameters: {'C': 0.00012530124812046257, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:33,986] Trial 20 finished with value: 0.583363288844735 and parameters: {'C': 0.48748121092082763, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:34,208] Trial 21 finished with value: 0.5877285791020401 and parameters: {'C': 7.66935624552851, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:34,454] Trial 22 finished with value: 0.5883232598730439 and parameters: {'C': 4.407406513411367, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:34,676] Trial 23 finished with value: 0.5872771249554194 and parameters: {'C': 2.5596825831781715, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:34,930] Trial 24 finished with value: 0.5867931246419568 and parameters: {'C': 1.158203016614606, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:35,170] Trial 25 finished with value: 0.5850028121691905 and parameters: {'C': 0.24614259243739703, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:35,401] Trial 26 finished with value: 0.586713372631688 and parameters: {'C': 3.174738605098387, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:35,601] Trial 27 finished with value: 0.581314248993495 and parameters: {'C': 0.033687361486735797, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:35,833] Trial 28 finished with value: 0.5876674195363961 and parameters: {'C': 4.364862939412637, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:36,084] Trial 29 finished with value: 0.5863306256363371 and parameters: {'C': 0.6296296776027592, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:36,319] Trial 30 finished with value: 0.5854561735338116 and parameters: {'C': 1.1333040721435979, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:36,536] Trial 31 finished with value: 0.586409929159811 and parameters: {'C': 9.687533043391914, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:36,753] Trial 32 finished with value: 0.5868079290360543 and parameters: {'C': 5.699397127765248, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:36,980] Trial 33 finished with value: 0.5857505763401847 and parameters: {'C': 2.899777197077893, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:38,694] Trial 34 finished with value: 0.5064525385510547 and parameters: {'C': 1.9511182883573746, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:38,952] Trial 35 finished with value: 0.5871784150808541 and parameters: {'C': 4.570419945350532, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:39,173] Trial 36 finished with value: 0.5884800895091362 and parameters: {'C': 9.956575803383815, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:40,880] Trial 37 finished with value: 0.5064525385510547 and parameters: {'C': 0.2689865919761259, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:41,159] Trial 38 finished with value: 0.5380299040053931 and parameters: {'C': 0.014650336600357756, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:42,865] Trial 39 finished with value: 0.5064525385510547 and parameters: {'C': 1.742737589051135, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:43,098] Trial 40 finished with value: 0.5871716250860065 and parameters: {'C': 5.621492491399746, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:43,330] Trial 41 finished with value: 0.5871186892395996 and parameters: {'C': 9.535105427894203, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:43,521] Trial 42 finished with value: 0.5859247580020571 and parameters: {'C': 4.1370833865322405, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:43,697] Trial 43 finished with value: 0.5549808600055434 and parameters: {'C': 0.0010884363586752546, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:43,936] Trial 44 finished with value: 0.5867944312001884 and parameters: {'C': 0.7909942868618163, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:44,166] Trial 45 finished with value: 0.5882579460080576 and parameters: {'C': 6.711396408119322, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 18:06:45,864] Trial 46 finished with value: 0.5064525385510547 and parameters: {'C': 2.92912957375267, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:46,081] Trial 47 finished with value: 0.5870003631672767 and parameters: {'C': 5.644654758464816, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:46,309] Trial 48 finished with value: 0.5853066061013343 and parameters: {'C': 2.005743895922345, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\3708829707.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 18:06:46,694] Trial 49 finished with value: 0.5876210585242784 and parameters: {'C': 6.127509076851761, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 15 with value: 0.5889897940669133.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best Parameters {'C': 2.6179180695948627, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "def objective_lr(trial):\n",
    "    params={\n",
    "        'C':trial.suggest_loguniform('C',1e-4,10),\n",
    "        'penalty':trial.suggest_categorical('penalty',['l1','l2']),\n",
    "        'solver':trial.suggest_categorical('solver',['liblinear','saga'])\n",
    "    }\n",
    "    model=LogisticRegression(**params,random_state=42)\n",
    "    return cross_val_score(model,X_train,y_train,cv=5,scoring='f1').mean()\n",
    "\n",
    "study_lr = optuna.create_study(direction='maximize')\n",
    "study_lr.optimize(objective_lr,n_trials=50)\n",
    "print(\"Logistic Regression Best Parameters\",study_lr.best_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42376ecd-64e2-4dba-aa34-9ab9335d03ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86      1033\n",
      "           1       0.63      0.47      0.54       374\n",
      "\n",
      "    accuracy                           0.79      1407\n",
      "   macro avg       0.73      0.68      0.70      1407\n",
      "weighted avg       0.77      0.79      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_lr = LogisticRegression(**study_lr.best_params)\n",
    "best_model_lr.fit(X_train,y_train)\n",
    "y_pred_lr = best_model_lr.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_lr,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efcc885e-481d-4641-bba4-278e6481a05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 18:07:01,367] A new study created in memory with name: no-name-2df643a4-fd3c-47b5-890e-7d61f43cd912\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:04,774] Trial 0 finished with value: 0.5778916052052004 and parameters: {'n_estimators': 157, 'max_depth': 12, 'learning_rate': 0.12744729569312163, 'subsample': 0.725856586524939, 'colsample_bytree': 0.6323034825887224}. Best is trial 0 with value: 0.5778916052052004.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:09,562] Trial 1 finished with value: 0.5722733273883202 and parameters: {'n_estimators': 172, 'max_depth': 15, 'learning_rate': 0.030435220302037012, 'subsample': 0.7302694924082559, 'colsample_bytree': 0.9709632362176893}. Best is trial 0 with value: 0.5778916052052004.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:13,899] Trial 2 finished with value: 0.5300354711843849 and parameters: {'n_estimators': 124, 'max_depth': 17, 'learning_rate': 0.012925319510981852, 'subsample': 0.9427420479771569, 'colsample_bytree': 0.9394674623609595}. Best is trial 0 with value: 0.5778916052052004.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:16,390] Trial 3 finished with value: 0.593004334142232 and parameters: {'n_estimators': 405, 'max_depth': 3, 'learning_rate': 0.10365950361657177, 'subsample': 0.8554665623302509, 'colsample_bytree': 0.8098261747541919}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:28,970] Trial 4 finished with value: 0.5683988852356896 and parameters: {'n_estimators': 448, 'max_depth': 19, 'learning_rate': 0.017748194548525636, 'subsample': 0.5512649518406192, 'colsample_bytree': 0.7323211877367963}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:33,254] Trial 5 finished with value: 0.5771563660228177 and parameters: {'n_estimators': 223, 'max_depth': 11, 'learning_rate': 0.019807026898872135, 'subsample': 0.5051270112940964, 'colsample_bytree': 0.5270627751105131}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:37,538] Trial 6 finished with value: 0.5680788296547818 and parameters: {'n_estimators': 180, 'max_depth': 13, 'learning_rate': 0.06632958930814777, 'subsample': 0.9353773612354768, 'colsample_bytree': 0.771035744822607}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:41,370] Trial 7 finished with value: 0.5715775706995997 and parameters: {'n_estimators': 243, 'max_depth': 9, 'learning_rate': 0.09667978999402436, 'subsample': 0.562626300487592, 'colsample_bytree': 0.8749117259178139}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:45,739] Trial 8 finished with value: 0.555068305199442 and parameters: {'n_estimators': 194, 'max_depth': 14, 'learning_rate': 0.26718142799284644, 'subsample': 0.6582270473962933, 'colsample_bytree': 0.5923732985668735}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:50,188] Trial 9 finished with value: 0.5710030914737153 and parameters: {'n_estimators': 230, 'max_depth': 10, 'learning_rate': 0.011199039087873073, 'subsample': 0.7980759183756572, 'colsample_bytree': 0.6582828631161657}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:52,681] Trial 10 finished with value: 0.5774054958464292 and parameters: {'n_estimators': 398, 'max_depth': 3, 'learning_rate': 0.24092459890629503, 'subsample': 0.8432824853336693, 'colsample_bytree': 0.838728240741974}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:07:56,062] Trial 11 finished with value: 0.5733427428036068 and parameters: {'n_estimators': 314, 'max_depth': 6, 'learning_rate': 0.11900108484744586, 'subsample': 0.7053996577448314, 'colsample_bytree': 0.6694877793492442}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:07:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:00,266] Trial 12 finished with value: 0.5632620654682652 and parameters: {'n_estimators': 358, 'max_depth': 7, 'learning_rate': 0.1471248001294665, 'subsample': 0.8459070318589151, 'colsample_bytree': 0.7705540181738881}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:05,259] Trial 13 finished with value: 0.582581372173597 and parameters: {'n_estimators': 499, 'max_depth': 6, 'learning_rate': 0.0437271511985874, 'subsample': 0.9950613246778253, 'colsample_bytree': 0.6694036865701007}. Best is trial 3 with value: 0.593004334142232.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:08,220] Trial 14 finished with value: 0.6016899108579224 and parameters: {'n_estimators': 497, 'max_depth': 3, 'learning_rate': 0.050604589923101746, 'subsample': 0.9676876811220133, 'colsample_bytree': 0.8321437418062998}. Best is trial 14 with value: 0.6016899108579224.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:11,200] Trial 15 finished with value: 0.6041659171375764 and parameters: {'n_estimators': 487, 'max_depth': 3, 'learning_rate': 0.058005419836617986, 'subsample': 0.8904034288132168, 'colsample_bytree': 0.8630465892401546}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:14,701] Trial 16 finished with value: 0.6000639628027412 and parameters: {'n_estimators': 493, 'max_depth': 4, 'learning_rate': 0.05651132136210433, 'subsample': 0.9290449663320003, 'colsample_bytree': 0.9002264033396817}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:20,929] Trial 17 finished with value: 0.5819358342754484 and parameters: {'n_estimators': 446, 'max_depth': 8, 'learning_rate': 0.03793675415276386, 'subsample': 0.9749832898352144, 'colsample_bytree': 0.9040887324949297}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:23,832] Trial 18 finished with value: 0.5867857864468189 and parameters: {'n_estimators': 312, 'max_depth': 5, 'learning_rate': 0.07401208319291033, 'subsample': 0.8930449753296139, 'colsample_bytree': 0.9858431567226313}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:27,956] Trial 19 finished with value: 0.5928732726197694 and parameters: {'n_estimators': 451, 'max_depth': 5, 'learning_rate': 0.03112777788225538, 'subsample': 0.7959665729152112, 'colsample_bytree': 0.8310982289606933}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:33,214] Trial 20 finished with value: 0.5825742821775161 and parameters: {'n_estimators': 367, 'max_depth': 8, 'learning_rate': 0.020965629786077272, 'subsample': 0.8956077645571321, 'colsample_bytree': 0.715857432694647}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:36,177] Trial 21 finished with value: 0.5944310835327571 and parameters: {'n_estimators': 481, 'max_depth': 3, 'learning_rate': 0.05849624671256414, 'subsample': 0.9237308432287834, 'colsample_bytree': 0.8982198202681002}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:39,750] Trial 22 finished with value: 0.5879549721393668 and parameters: {'n_estimators': 472, 'max_depth': 4, 'learning_rate': 0.04755862103515035, 'subsample': 0.9748459918324676, 'colsample_bytree': 0.8704168131071242}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:43,513] Trial 23 finished with value: 0.5830813842211637 and parameters: {'n_estimators': 409, 'max_depth': 5, 'learning_rate': 0.07407851593898884, 'subsample': 0.9015043956238419, 'colsample_bytree': 0.9318535242492875}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:46,604] Trial 24 finished with value: 0.5998167923597054 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.03353178053809265, 'subsample': 0.7943691587523733, 'colsample_bytree': 0.8044350879982148}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:51,118] Trial 25 finished with value: 0.5644325715396181 and parameters: {'n_estimators': 430, 'max_depth': 6, 'learning_rate': 0.16685152204059928, 'subsample': 0.9999902150829778, 'colsample_bytree': 0.8627205737916136}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:08:53,828] Trial 26 finished with value: 0.5987783146157024 and parameters: {'n_estimators': 347, 'max_depth': 4, 'learning_rate': 0.05110566139522017, 'subsample': 0.9488204930825538, 'colsample_bytree': 0.9387021204719159}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:08:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:00,398] Trial 27 finished with value: 0.5828107396791706 and parameters: {'n_estimators': 471, 'max_depth': 8, 'learning_rate': 0.025188602925230823, 'subsample': 0.8699380766054811, 'colsample_bytree': 0.798513869081258}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:03,638] Trial 28 finished with value: 0.5908707493076839 and parameters: {'n_estimators': 423, 'max_depth': 4, 'learning_rate': 0.0924992343293842, 'subsample': 0.6718173361016473, 'colsample_bytree': 0.9015267439075398}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:10,936] Trial 29 finished with value: 0.5597268391994825 and parameters: {'n_estimators': 382, 'max_depth': 11, 'learning_rate': 0.06119472271138291, 'subsample': 0.8271899567671909, 'colsample_bytree': 0.8449811963301354}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:14,335] Trial 30 finished with value: 0.5831777856864473 and parameters: {'n_estimators': 270, 'max_depth': 7, 'learning_rate': 0.04313249817540116, 'subsample': 0.7710069134770834, 'colsample_bytree': 0.7091872334096548}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:17,445] Trial 31 finished with value: 0.594356358604721 and parameters: {'n_estimators': 499, 'max_depth': 3, 'learning_rate': 0.03454435811103529, 'subsample': 0.8059901454412662, 'colsample_bytree': 0.8000157053964435}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:21,215] Trial 32 finished with value: 0.5969899272053127 and parameters: {'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.026798269012672876, 'subsample': 0.7446792985744062, 'colsample_bytree': 0.7797003678946212}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:25,417] Trial 33 finished with value: 0.5833495024263817 and parameters: {'n_estimators': 465, 'max_depth': 5, 'learning_rate': 0.08189317726698316, 'subsample': 0.9180745090311851, 'colsample_bytree': 0.9634033545915274}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:28,129] Trial 34 finished with value: 0.5990673684674507 and parameters: {'n_estimators': 433, 'max_depth': 3, 'learning_rate': 0.03797589403843824, 'subsample': 0.9587056712432334, 'colsample_bytree': 0.8217227554800368}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:41,063] Trial 35 finished with value: 0.5607429171217881 and parameters: {'n_estimators': 470, 'max_depth': 17, 'learning_rate': 0.05558980315211427, 'subsample': 0.881294374949168, 'colsample_bytree': 0.8835040367606433}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:41,921] Trial 36 finished with value: 0.440958944658719 and parameters: {'n_estimators': 118, 'max_depth': 3, 'learning_rate': 0.013991285157058315, 'subsample': 0.7698851383190136, 'colsample_bytree': 0.7459350828054012}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:09:58,207] Trial 37 finished with value: 0.5580080992193397 and parameters: {'n_estimators': 482, 'max_depth': 20, 'learning_rate': 0.026015932914718484, 'subsample': 0.9226236772073519, 'colsample_bytree': 0.9574286107938345}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:09:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:09,916] Trial 38 finished with value: 0.5609320694583634 and parameters: {'n_estimators': 453, 'max_depth': 16, 'learning_rate': 0.06609510980479177, 'subsample': 0.8613808628286431, 'colsample_bytree': 0.9288008236359652}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:14,693] Trial 39 finished with value: 0.593435996672597 and parameters: {'n_estimators': 406, 'max_depth': 7, 'learning_rate': 0.01688085028396691, 'subsample': 0.9570665544280255, 'colsample_bytree': 0.8569397669662219}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:17,940] Trial 40 finished with value: 0.5946817177824822 and parameters: {'n_estimators': 442, 'max_depth': 4, 'learning_rate': 0.03291099776805498, 'subsample': 0.7067744021517333, 'colsample_bytree': 0.8115169989928354}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:20,619] Trial 41 finished with value: 0.5996254764947034 and parameters: {'n_estimators': 428, 'max_depth': 3, 'learning_rate': 0.04391700217794861, 'subsample': 0.9573476159268726, 'colsample_bytree': 0.816428752627998}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:23,640] Trial 42 finished with value: 0.597383270029975 and parameters: {'n_estimators': 485, 'max_depth': 3, 'learning_rate': 0.042080815735629266, 'subsample': 0.9756357661127983, 'colsample_bytree': 0.7804421826251694}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:27,694] Trial 43 finished with value: 0.5888730606270115 and parameters: {'n_estimators': 457, 'max_depth': 5, 'learning_rate': 0.05235452854401207, 'subsample': 0.9414942504464896, 'colsample_bytree': 0.8391009912859637}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:28,880] Trial 44 finished with value: 0.5960143249874393 and parameters: {'n_estimators': 139, 'max_depth': 4, 'learning_rate': 0.08384994182174765, 'subsample': 0.9087307516477139, 'colsample_bytree': 0.9142450211515796}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:39,205] Trial 45 finished with value: 0.5548092861691749 and parameters: {'n_estimators': 489, 'max_depth': 13, 'learning_rate': 0.11182861717344668, 'subsample': 0.8341769728950078, 'colsample_bytree': 0.7592420312969228}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:43,632] Trial 46 finished with value: 0.5879404325816902 and parameters: {'n_estimators': 416, 'max_depth': 6, 'learning_rate': 0.03810550279811001, 'subsample': 0.8786335706781644, 'colsample_bytree': 0.8761002143996727}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:46,720] Trial 47 finished with value: 0.5967175785225703 and parameters: {'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.048080576529562054, 'subsample': 0.936226372121626, 'colsample_bytree': 0.5570851063161761}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:53,025] Trial 48 finished with value: 0.5776591465816732 and parameters: {'n_estimators': 389, 'max_depth': 9, 'learning_rate': 0.021018968158469056, 'subsample': 0.6117138869131707, 'colsample_bytree': 0.8020123667660541}. Best is trial 15 with value: 0.6041659171375764.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2726214603.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [18:10:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 18:10:57,028] Trial 49 finished with value: 0.5916901268658857 and parameters: {'n_estimators': 442, 'max_depth': 5, 'learning_rate': 0.029706143964752, 'subsample': 0.9858605846078307, 'colsample_bytree': 0.9945841924640509}. Best is trial 15 with value: 0.6041659171375764.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Best Parameters {'n_estimators': 487, 'max_depth': 3, 'learning_rate': 0.058005419836617986, 'subsample': 0.8904034288132168, 'colsample_bytree': 0.8630465892401546}\n"
     ]
    }
   ],
   "source": [
    "#XGBoost classifier\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators':trial.suggest_int('n_estimators',100,500),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,20),\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
    "        'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
    "        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
    "    }\n",
    "    model=XGBClassifier(**params,use_label_encoder=False,eval_metric='logloss',random_state=42)\n",
    "    return cross_val_score(model,X_train,y_train,cv=5,scoring='f1').mean()\n",
    "\n",
    "study_xgb = optuna.create_study(direction='maximize')\n",
    "study_xgb.optimize(objective_xgb,n_trials=50) \n",
    "print(\"XGBoost Classifier Best Parameters\",study_xgb.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d47f4c1-87a9-4f64-8728-5a23c3025161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1033\n",
      "           1       0.64      0.52      0.57       374\n",
      "\n",
      "    accuracy                           0.79      1407\n",
      "   macro avg       0.74      0.71      0.72      1407\n",
      "weighted avg       0.78      0.79      0.79      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_xgb = XGBClassifier(**study_xgb.best_params)\n",
    "best_model_xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = best_model_xgb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_xgb,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "420b35be-2f77-465f-9005-a18c5e91bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "#random forest\n",
    "best_model_rf = RandomForestClassifier(**study_rf.best_params)\n",
    "best_model_rf.fit(X_train,y_train)\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "f1_rf = f1_score(y_test,y_pred_rf,average='weighted')\n",
    "\n",
    "result.append({\n",
    "    'model':'Random Forest','f1_score':f1_rf,'params':study_rf.best_params\n",
    "})\n",
    "\n",
    "#decision tree\n",
    "best_model_dt = DecisionTreeClassifier(**study_dt.best_params)\n",
    "best_model_dt.fit(X_train,y_train)\n",
    "y_pred_dt = best_model_dt.predict(X_test)\n",
    "f1_dt = f1_score(y_test,y_pred_dt,average='weighted')\n",
    "\n",
    "result.append({\n",
    "    'model':'Decision Tree','f1_score':f1_dt,'params':study_dt.best_params\n",
    "})\n",
    "\n",
    "#Logistic Regression\n",
    "\n",
    "best_model_lr = LogisticRegression(**study_lr.best_params)\n",
    "best_model_lr.fit(X_train,y_train)\n",
    "y_pred_lr = best_model_lr.predict(X_test)\n",
    "f1_lr = f1_score(y_test,y_pred_lr,average='weighted')\n",
    "\n",
    "result.append({\n",
    "    'model':'LogisticRegression','f1_score':f1_lr,'params':study_lr.best_params\n",
    "})\n",
    "\n",
    "\n",
    "#XGBoost\n",
    "best_model_xgb = XGBClassifier(**study_xgb.best_params)\n",
    "best_model_xgb.fit(X_train,y_train)\n",
    "y_pred_xgb = best_model_xgb.predict(X_test)\n",
    "f1_xgb = f1_score(y_test,y_pred_xgb,average='weighted')\n",
    "\n",
    "result.append({\n",
    "    'model':'XGBoost','f1_score':f1_xgb,'params':study_xgb.best_params\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d12f489b-aa61-49d6-abb0-662991776525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                model  f1_score  \\\n",
      "0       Random Forest  0.767922   \n",
      "3             XGBoost  0.766080   \n",
      "1       Decision Tree  0.763016   \n",
      "2  LogisticRegression  0.740665   \n",
      "\n",
      "                                              params  \n",
      "0  {'n_estimators': 383, 'max_depth': 14, 'min_sa...  \n",
      "3  {'n_estimators': 192, 'max_depth': 14, 'learni...  \n",
      "1  {'max_depth': 6, 'min_samples_split': 14, 'min...  \n",
      "2  {'C': 0.4960411096906256, 'penalty': 'l2', 'so...  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(result)\n",
    "results_df=results_df.sort_values(by='f1_score',ascending=False)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fc64b09-1c1c-474b-a8fc-0db2eb914b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTETo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "032c10d7-38e9-4928-a2f4-c06d0074a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 4130, 1: 1495})\n",
      "After SMOTE Counter({1: 2448, 0: 2176})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTEENN(random_state=42)\n",
    "X_resampled,y_resampled = sm.fit_resample(X_train,y_train)\n",
    "print(\"Before SMOTE:\",Counter(y_train))\n",
    "print(\"After SMOTE\",Counter(y_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b56fa17-87d7-4e9f-9ccc-79cf77d21a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 20:08:08,297] A new study created in memory with name: no-name-9766ee85-1d92-4c03-8908-02dd14bd8710\n",
      "[I 2025-06-25 20:08:26,974] Trial 0 finished with value: 0.9497808594550797 and parameters: {'n_estimators': 476, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9497808594550797.\n",
      "[I 2025-06-25 20:08:39,480] Trial 1 finished with value: 0.9506735242392976 and parameters: {'n_estimators': 300, 'max_depth': 22, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9506735242392976.\n",
      "[I 2025-06-25 20:08:46,219] Trial 2 finished with value: 0.9486275715779187 and parameters: {'n_estimators': 166, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9506735242392976.\n",
      "[I 2025-06-25 20:08:49,981] Trial 3 finished with value: 0.9056554873594933 and parameters: {'n_estimators': 151, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9506735242392976.\n",
      "[I 2025-06-25 20:09:06,978] Trial 4 finished with value: 0.9542276647941741 and parameters: {'n_estimators': 383, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:09:21,822] Trial 5 finished with value: 0.9508714576559765 and parameters: {'n_estimators': 362, 'max_depth': 13, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:09:30,694] Trial 6 finished with value: 0.9466418664666124 and parameters: {'n_estimators': 245, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:09:48,708] Trial 7 finished with value: 0.9500690039696309 and parameters: {'n_estimators': 436, 'max_depth': 28, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:09:53,999] Trial 8 finished with value: 0.9476962176722752 and parameters: {'n_estimators': 132, 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:10:07,305] Trial 9 finished with value: 0.9481533680161484 and parameters: {'n_estimators': 336, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:10:25,146] Trial 10 finished with value: 0.9517527736135815 and parameters: {'n_estimators': 404, 'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:10:42,834] Trial 11 finished with value: 0.9519455632800554 and parameters: {'n_estimators': 401, 'max_depth': 24, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:11:04,437] Trial 12 finished with value: 0.9516987361842519 and parameters: {'n_estimators': 493, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:11:16,440] Trial 13 finished with value: 0.951047686150274 and parameters: {'n_estimators': 272, 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:11:33,630] Trial 14 finished with value: 0.9522132693319338 and parameters: {'n_estimators': 401, 'max_depth': 18, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:11:49,258] Trial 15 finished with value: 0.9522157986721795 and parameters: {'n_estimators': 356, 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:11:58,256] Trial 16 finished with value: 0.9523859919342129 and parameters: {'n_estimators': 209, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:07,003] Trial 17 finished with value: 0.9518763570152109 and parameters: {'n_estimators': 213, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:13,393] Trial 18 finished with value: 0.9250463288091717 and parameters: {'n_estimators': 208, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:18,480] Trial 19 finished with value: 0.9528954333634749 and parameters: {'n_estimators': 112, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:23,012] Trial 20 finished with value: 0.9531117695757155 and parameters: {'n_estimators': 100, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:28,419] Trial 21 finished with value: 0.9526561933412871 and parameters: {'n_estimators': 122, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:32,510] Trial 22 finished with value: 0.9482679117850262 and parameters: {'n_estimators': 106, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:39,278] Trial 23 finished with value: 0.9526860150745042 and parameters: {'n_estimators': 153, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:43,709] Trial 24 finished with value: 0.9502768625464544 and parameters: {'n_estimators': 101, 'max_depth': 20, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:12:50,788] Trial 25 finished with value: 0.9503516404048116 and parameters: {'n_estimators': 172, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:13:02,181] Trial 26 finished with value: 0.9445145812866123 and parameters: {'n_estimators': 319, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:13:13,479] Trial 27 finished with value: 0.9516364578755521 and parameters: {'n_estimators': 255, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:13:32,512] Trial 28 finished with value: 0.9527335571980334 and parameters: {'n_estimators': 447, 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:13:43,913] Trial 29 finished with value: 0.9486823514017537 and parameters: {'n_estimators': 297, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:13:51,680] Trial 30 finished with value: 0.9514103458702842 and parameters: {'n_estimators': 180, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:14:10,492] Trial 31 finished with value: 0.9525131704688728 and parameters: {'n_estimators': 444, 'max_depth': 12, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:14:28,206] Trial 32 finished with value: 0.9521141952550701 and parameters: {'n_estimators': 440, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:14:50,472] Trial 33 finished with value: 0.9531665412660366 and parameters: {'n_estimators': 474, 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:15:07,905] Trial 34 finished with value: 0.9520171397352637 and parameters: {'n_estimators': 374, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:15:28,972] Trial 35 finished with value: 0.9529087661283671 and parameters: {'n_estimators': 461, 'max_depth': 21, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:15:51,066] Trial 36 finished with value: 0.952886322834803 and parameters: {'n_estimators': 479, 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:16:12,158] Trial 37 finished with value: 0.9527006233122183 and parameters: {'n_estimators': 468, 'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:16:29,471] Trial 38 finished with value: 0.9500589476349204 and parameters: {'n_estimators': 420, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:16:44,557] Trial 39 finished with value: 0.9406794023541847 and parameters: {'n_estimators': 468, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:16:59,879] Trial 40 finished with value: 0.9482130137318278 and parameters: {'n_estimators': 377, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:17:20,996] Trial 41 finished with value: 0.9542128060038918 and parameters: {'n_estimators': 494, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:17:43,501] Trial 42 finished with value: 0.9528751061415915 and parameters: {'n_estimators': 497, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:18:03,354] Trial 43 finished with value: 0.9539729252165928 and parameters: {'n_estimators': 461, 'max_depth': 13, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:18:21,137] Trial 44 finished with value: 0.9510989785649896 and parameters: {'n_estimators': 427, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:18:42,335] Trial 45 finished with value: 0.9540067090003767 and parameters: {'n_estimators': 487, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:19:03,485] Trial 46 finished with value: 0.9516515574623694 and parameters: {'n_estimators': 500, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:19:24,005] Trial 47 finished with value: 0.9498047727615851 and parameters: {'n_estimators': 482, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:19:44,130] Trial 48 finished with value: 0.9507003298544824 and parameters: {'n_estimators': 458, 'max_depth': 17, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n",
      "[I 2025-06-25 20:20:02,070] Trial 49 finished with value: 0.9518505604989332 and parameters: {'n_estimators': 400, 'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 4 with value: 0.9542276647941741.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Parameters {'n_estimators': 383, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt'}\n"
     ]
    }
   ],
   "source": [
    "#random forest classifier\n",
    "def objective_rf1(trial):\n",
    "    params={\n",
    "        'n_estimators':trial.suggest_int('n_estimators',100,500),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,30),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,10),\n",
    "        'min_samples_leaf':trial.suggest_int('min_samples_leaf',1,10),\n",
    "        'max_features':trial.suggest_categorical('max_features',['log2','sqrt'])\n",
    "    }\n",
    "\n",
    "    model1=RandomForestClassifier(**params,random_state=42)\n",
    "    return cross_val_score(model1,X_resampled,y_resampled,cv=5,scoring='f1').mean()\n",
    "\n",
    "study_rf1 = optuna.create_study(direction='maximize')\n",
    "study_rf1.optimize(objective_rf1,n_trials=50)\n",
    "print(\"Random Forest Best Parameters\",study_rf1.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "865bce8c-c55a-41c5-9dbe-c14cd8ea7112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83      1033\n",
      "           1       0.55      0.80      0.65       374\n",
      "\n",
      "    accuracy                           0.78      1407\n",
      "   macro avg       0.73      0.78      0.74      1407\n",
      "weighted avg       0.82      0.78      0.79      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_rf1 = RandomForestClassifier(**study_rf1.best_params)\n",
    "best_model_rf1.fit(X_resampled,y_resampled)\n",
    "y_pred_rf1 = best_model_rf1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_rf1,labels=[0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecc4a4fb-c343-4465-81fb-cfdde0d978e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 20:22:31,508] A new study created in memory with name: no-name-ae00b392-0e24-4a31-b147-c38832ddc541\n",
      "[I 2025-06-25 20:22:31,847] Trial 0 finished with value: 0.9403139930939707 and parameters: {'max_depth': 26, 'min_samples_split': 20, 'min_samples_leaf': 7, 'criterion': 'entropy'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:32,165] Trial 1 finished with value: 0.9254651596253025 and parameters: {'max_depth': 27, 'min_samples_split': 4, 'min_samples_leaf': 17, 'criterion': 'gini'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:32,481] Trial 2 finished with value: 0.925569609824892 and parameters: {'max_depth': 25, 'min_samples_split': 13, 'min_samples_leaf': 16, 'criterion': 'gini'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:32,787] Trial 3 finished with value: 0.926425286089081 and parameters: {'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 10, 'criterion': 'gini'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:33,103] Trial 4 finished with value: 0.925569609824892 and parameters: {'max_depth': 23, 'min_samples_split': 15, 'min_samples_leaf': 16, 'criterion': 'gini'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:33,404] Trial 5 finished with value: 0.9373854659380237 and parameters: {'max_depth': 21, 'min_samples_split': 13, 'min_samples_leaf': 16, 'criterion': 'entropy'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:33,726] Trial 6 finished with value: 0.9403139930939707 and parameters: {'max_depth': 26, 'min_samples_split': 20, 'min_samples_leaf': 7, 'criterion': 'entropy'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:34,049] Trial 7 finished with value: 0.9243593112697399 and parameters: {'max_depth': 29, 'min_samples_split': 20, 'min_samples_leaf': 12, 'criterion': 'gini'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:34,355] Trial 8 finished with value: 0.9381013502116993 and parameters: {'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 11, 'criterion': 'entropy'}. Best is trial 0 with value: 0.9403139930939707.\n",
      "[I 2025-06-25 20:22:34,671] Trial 9 finished with value: 0.9462137368762846 and parameters: {'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy'}. Best is trial 9 with value: 0.9462137368762846.\n",
      "[I 2025-06-25 20:22:35,052] Trial 10 finished with value: 0.9391422505017719 and parameters: {'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 1, 'criterion': 'entropy'}. Best is trial 9 with value: 0.9462137368762846.\n",
      "[I 2025-06-25 20:22:35,390] Trial 11 finished with value: 0.9466073481003576 and parameters: {'max_depth': 18, 'min_samples_split': 17, 'min_samples_leaf': 3, 'criterion': 'entropy'}. Best is trial 11 with value: 0.9466073481003576.\n",
      "[I 2025-06-25 20:22:35,646] Trial 12 finished with value: 0.8665590570418056 and parameters: {'max_depth': 3, 'min_samples_split': 16, 'min_samples_leaf': 1, 'criterion': 'entropy'}. Best is trial 11 with value: 0.9466073481003576.\n",
      "[I 2025-06-25 20:22:36,057] Trial 13 finished with value: 0.9462137368762846 and parameters: {'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 4, 'criterion': 'entropy'}. Best is trial 11 with value: 0.9466073481003576.\n",
      "[I 2025-06-25 20:22:36,404] Trial 14 finished with value: 0.9440573264794851 and parameters: {'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 5, 'criterion': 'entropy'}. Best is trial 11 with value: 0.9466073481003576.\n",
      "[I 2025-06-25 20:22:36,749] Trial 15 finished with value: 0.9467362660625789 and parameters: {'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 4, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:37,097] Trial 16 finished with value: 0.9393680550489355 and parameters: {'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 8, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:37,412] Trial 17 finished with value: 0.9392328934864809 and parameters: {'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 20, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:37,764] Trial 18 finished with value: 0.9418393904925644 and parameters: {'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 2, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:38,100] Trial 19 finished with value: 0.94459611696203 and parameters: {'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 3, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:38,333] Trial 20 finished with value: 0.8665590570418056 and parameters: {'max_depth': 3, 'min_samples_split': 18, 'min_samples_leaf': 6, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:38,683] Trial 21 finished with value: 0.9462137368762846 and parameters: {'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 4, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:39,020] Trial 22 finished with value: 0.9413432026833732 and parameters: {'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 9, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:39,367] Trial 23 finished with value: 0.9434996182963223 and parameters: {'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 3, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:39,701] Trial 24 finished with value: 0.942463171420956 and parameters: {'max_depth': 20, 'min_samples_split': 11, 'min_samples_leaf': 13, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:40,009] Trial 25 finished with value: 0.9269559789779619 and parameters: {'max_depth': 6, 'min_samples_split': 18, 'min_samples_leaf': 5, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:40,375] Trial 26 finished with value: 0.9269235896613477 and parameters: {'max_depth': 16, 'min_samples_split': 5, 'min_samples_leaf': 3, 'criterion': 'gini'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:40,717] Trial 27 finished with value: 0.9413251721396719 and parameters: {'max_depth': 11, 'min_samples_split': 15, 'min_samples_leaf': 6, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:41,067] Trial 28 finished with value: 0.9406191440228499 and parameters: {'max_depth': 23, 'min_samples_split': 10, 'min_samples_leaf': 1, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:41,397] Trial 29 finished with value: 0.9344350339822268 and parameters: {'max_depth': 8, 'min_samples_split': 19, 'min_samples_leaf': 8, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:41,741] Trial 30 finished with value: 0.9394051503017516 and parameters: {'max_depth': 30, 'min_samples_split': 16, 'min_samples_leaf': 6, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:42,086] Trial 31 finished with value: 0.9462137368762846 and parameters: {'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 4, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:42,436] Trial 32 finished with value: 0.9462137368762846 and parameters: {'max_depth': 16, 'min_samples_split': 4, 'min_samples_leaf': 4, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:42,794] Trial 33 finished with value: 0.9423098392452216 and parameters: {'max_depth': 16, 'min_samples_split': 2, 'min_samples_leaf': 2, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:43,156] Trial 34 finished with value: 0.9320985535692792 and parameters: {'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 5, 'criterion': 'gini'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:43,517] Trial 35 finished with value: 0.9227971246078838 and parameters: {'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 8, 'criterion': 'gini'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:43,876] Trial 36 finished with value: 0.9416318345321653 and parameters: {'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 2, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:44,257] Trial 37 finished with value: 0.9464205797270868 and parameters: {'max_depth': 19, 'min_samples_split': 13, 'min_samples_leaf': 4, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:44,623] Trial 38 finished with value: 0.926150097590636 and parameters: {'max_depth': 27, 'min_samples_split': 13, 'min_samples_leaf': 7, 'criterion': 'gini'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:44,960] Trial 39 finished with value: 0.9413432026833732 and parameters: {'max_depth': 21, 'min_samples_split': 14, 'min_samples_leaf': 9, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:45,313] Trial 40 finished with value: 0.9228458508827316 and parameters: {'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 13, 'criterion': 'gini'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:45,663] Trial 41 finished with value: 0.9462137368762846 and parameters: {'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 4, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:46,014] Trial 42 finished with value: 0.9466073481003576 and parameters: {'max_depth': 19, 'min_samples_split': 17, 'min_samples_leaf': 3, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:46,365] Trial 43 finished with value: 0.9466971602580099 and parameters: {'max_depth': 20, 'min_samples_split': 19, 'min_samples_leaf': 3, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:46,717] Trial 44 finished with value: 0.9456633574328018 and parameters: {'max_depth': 20, 'min_samples_split': 19, 'min_samples_leaf': 2, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:47,065] Trial 45 finished with value: 0.9466073481003576 and parameters: {'max_depth': 19, 'min_samples_split': 17, 'min_samples_leaf': 3, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:47,414] Trial 46 finished with value: 0.9462919134156221 and parameters: {'max_depth': 22, 'min_samples_split': 20, 'min_samples_leaf': 1, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:47,770] Trial 47 finished with value: 0.9466073481003576 and parameters: {'max_depth': 14, 'min_samples_split': 17, 'min_samples_leaf': 3, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:48,118] Trial 48 finished with value: 0.9456633574328018 and parameters: {'max_depth': 19, 'min_samples_split': 19, 'min_samples_leaf': 2, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n",
      "[I 2025-06-25 20:22:48,463] Trial 49 finished with value: 0.9427910560406433 and parameters: {'max_depth': 21, 'min_samples_split': 17, 'min_samples_leaf': 5, 'criterion': 'entropy'}. Best is trial 15 with value: 0.9467362660625789.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Best Parameters {'max_depth': 12, 'min_samples_split': 17, 'min_samples_leaf': 4, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "#Decision tree Classifier\n",
    "def objective_dt1(trial):\n",
    "    params1={\n",
    "        'max_depth':trial.suggest_int('max_depth',2,30),\n",
    "        'min_samples_split':trial.suggest_int('min_samples_split',2,20),\n",
    "        'min_samples_leaf':trial.suggest_int('min_samples_leaf',1,20),\n",
    "        'criterion':trial.suggest_categorical('criterion',['gini','entropy'])\n",
    "    }\n",
    "    \n",
    "    model1=DecisionTreeClassifier(**params1,random_state=42)\n",
    "    return cross_val_score(model1,X_resampled,y_resampled,cv=5,scoring='f1').mean()\n",
    "\n",
    "study_dt1 = optuna.create_study(direction='maximize')\n",
    "study_dt1.optimize(objective_dt1,n_trials=50)\n",
    "print(\"Decision Tree Best Parameters\",study_dt1.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5762001-7240-4c86-9b0f-e6e7215ceb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83      1033\n",
      "           1       0.53      0.65      0.59       374\n",
      "\n",
      "    accuracy                           0.76      1407\n",
      "   macro avg       0.70      0.72      0.71      1407\n",
      "weighted avg       0.77      0.76      0.76      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_dt1 = DecisionTreeClassifier(**study_dt1.best_params)\n",
    "best_model_dt1.fit(X_resampled,y_resampled)\n",
    "y_pred_dt1 = best_model_dt1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_dt1,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae0006a4-2783-4717-b44c-2211be371c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 20:25:25,181] A new study created in memory with name: no-name-a4df80a4-17e4-4334-9e80-bc676a2735c7\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:25,609] Trial 0 finished with value: 0.9142642212541263 and parameters: {'C': 0.03339868773672797, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 0 with value: 0.9142642212541263.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:25:27,538] Trial 1 finished with value: 0.8099456766350915 and parameters: {'C': 0.00839141827624196, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 0 with value: 0.9142642212541263.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:27,838] Trial 2 finished with value: 0.9186852874147309 and parameters: {'C': 4.515883211310181, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:28,570] Trial 3 finished with value: 0.9186189110713124 and parameters: {'C': 0.3316913658522463, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:25:30,513] Trial 4 finished with value: 0.8099456766350915 and parameters: {'C': 0.00465311635923938, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:25:33,089] Trial 5 finished with value: 0.8099456766350915 and parameters: {'C': 4.095918954366182, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:33,403] Trial 6 finished with value: 0.9146440882941189 and parameters: {'C': 0.035424847272419985, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:33,661] Trial 7 finished with value: 0.9147584827076314 and parameters: {'C': 0.04074804928567971, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:25:35,551] Trial 8 finished with value: 0.8099456766350915 and parameters: {'C': 0.6141494687645909, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:25:37,911] Trial 9 finished with value: 0.8097211857483526 and parameters: {'C': 0.004371867842128934, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:38,164] Trial 10 finished with value: 0.8381279655712776 and parameters: {'C': 0.0001327679374984448, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 2 with value: 0.9186852874147309.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:39,274] Trial 11 finished with value: 0.9189785701909792 and parameters: {'C': 8.663611594321738, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 11 with value: 0.9189785701909792.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:40,430] Trial 12 finished with value: 0.9187484190500941 and parameters: {'C': 8.25192649206605, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 11 with value: 0.9189785701909792.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:41,383] Trial 13 finished with value: 0.919228243094443 and parameters: {'C': 6.893164061112008, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 13 with value: 0.919228243094443.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:42,301] Trial 14 finished with value: 0.9192027629310473 and parameters: {'C': 0.6505368875224207, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 13 with value: 0.919228243094443.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:43,205] Trial 15 finished with value: 0.9189413279057537 and parameters: {'C': 0.7444243392856734, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 13 with value: 0.919228243094443.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:43,879] Trial 16 finished with value: 0.91917881250269 and parameters: {'C': 0.21345503022438206, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 13 with value: 0.919228243094443.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:45,027] Trial 17 finished with value: 0.9189608098285792 and parameters: {'C': 1.7668686250952963, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 13 with value: 0.919228243094443.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:45,605] Trial 18 finished with value: 0.9194002329659512 and parameters: {'C': 0.14310034848026107, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:45,782] Trial 19 finished with value: 0.8095007360400611 and parameters: {'C': 0.00038975283758240734, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:46,333] Trial 20 finished with value: 0.9181450201349894 and parameters: {'C': 0.12977375338963149, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:47,695] Trial 21 finished with value: 0.9191578782440771 and parameters: {'C': 0.9987775081527093, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:48,213] Trial 22 finished with value: 0.9180815478711353 and parameters: {'C': 0.11060079995593167, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:49,569] Trial 23 finished with value: 0.918958214406952 and parameters: {'C': 2.180873346368617, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:50,601] Trial 24 finished with value: 0.9185829824415774 and parameters: {'C': 1.5113996272280097, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:51,318] Trial 25 finished with value: 0.9186154123573498 and parameters: {'C': 0.3440882980187829, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:25:53,975] Trial 26 finished with value: 0.8095711705909319 and parameters: {'C': 0.015961707202774306, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:54,483] Trial 27 finished with value: 0.9177181873185042 and parameters: {'C': 0.09224486970093759, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:56,042] Trial 28 finished with value: 0.9185544829622986 and parameters: {'C': 3.11020876834314, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:56,229] Trial 29 finished with value: 0.808674652854488 and parameters: {'C': 0.001386389361425263, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:56,992] Trial 30 finished with value: 0.9183945363403494 and parameters: {'C': 0.5014424746581975, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 18 with value: 0.9194002329659512.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:57,626] Trial 31 finished with value: 0.9194026950091505 and parameters: {'C': 0.20738472208417505, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:58,105] Trial 32 finished with value: 0.9185961138898466 and parameters: {'C': 0.0710224006806723, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:58,802] Trial 33 finished with value: 0.9194026950091505 and parameters: {'C': 0.2065451353204908, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:25:59,303] Trial 34 finished with value: 0.8959083943188337 and parameters: {'C': 0.017714742422057908, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:26:02,086] Trial 35 finished with value: 0.8099456766350915 and parameters: {'C': 0.2422285058669837, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:02,398] Trial 36 finished with value: 0.9152340104052765 and parameters: {'C': 0.05564850014836597, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:03,017] Trial 37 finished with value: 0.9191815076805145 and parameters: {'C': 0.17232410388261543, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:26:05,470] Trial 38 finished with value: 0.8095711705909319 and parameters: {'C': 0.012246725613315036, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:05,732] Trial 39 finished with value: 0.9139393372362342 and parameters: {'C': 0.02858377080665366, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:26:08,056] Trial 40 finished with value: 0.8098697787785539 and parameters: {'C': 0.0025848521911382982, 'penalty': 'l1', 'solver': 'saga'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:08,750] Trial 41 finished with value: 0.9186161475000649 and parameters: {'C': 0.34642678855051723, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:09,814] Trial 42 finished with value: 0.9191578782440771 and parameters: {'C': 0.884594837692777, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:10,913] Trial 43 finished with value: 0.918398250494849 and parameters: {'C': 4.881844205469277, 'penalty': 'l1', 'solver': 'liblinear'}. Best is trial 31 with value: 0.9194026950091505.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:11,210] Trial 44 finished with value: 0.9197012550687186 and parameters: {'C': 0.4960411096906256, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 44 with value: 0.9197012550687186.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:11,510] Trial 45 finished with value: 0.9147903818366567 and parameters: {'C': 0.04000527129083863, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 44 with value: 0.9197012550687186.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:11,804] Trial 46 finished with value: 0.91658200970408 and parameters: {'C': 0.41392251062429875, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 44 with value: 0.9197012550687186.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:12,109] Trial 47 finished with value: 0.9168888449199365 and parameters: {'C': 0.17661118567441586, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 44 with value: 0.9197012550687186.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "[I 2025-06-25 20:26:12,420] Trial 48 finished with value: 0.9184088372311379 and parameters: {'C': 5.7659237941194785, 'penalty': 'l2', 'solver': 'liblinear'}. Best is trial 44 with value: 0.9197012550687186.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\1149095759.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'C':trial.suggest_loguniform('C',1e-4,10),\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-06-25 20:26:14,342] Trial 49 finished with value: 0.8099456766350915 and parameters: {'C': 3.0005948906819966, 'penalty': 'l2', 'solver': 'saga'}. Best is trial 44 with value: 0.9197012550687186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best Parameters {'C': 0.4960411096906256, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "def objective_lr1(trial):\n",
    "    params={\n",
    "        'C':trial.suggest_loguniform('C',1e-4,10),\n",
    "        'penalty':trial.suggest_categorical('penalty',['l1','l2']),\n",
    "        'solver':trial.suggest_categorical('solver',['liblinear','saga'])\n",
    "    }\n",
    "    model1=LogisticRegression(**params,random_state=42)\n",
    "    return cross_val_score(model1,X_resampled,y_resampled,cv=5,scoring='f1').mean()\n",
    "\n",
    "study_lr1 = optuna.create_study(direction='maximize')\n",
    "study_lr1.optimize(objective_lr1,n_trials=50)\n",
    "print(\"Logistic Regression Best Parameters\",study_lr1.best_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b872f12-0005-4c2d-a37c-4405b27bcb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.72      0.79      1033\n",
      "           1       0.49      0.76      0.60       374\n",
      "\n",
      "    accuracy                           0.73      1407\n",
      "   macro avg       0.69      0.74      0.69      1407\n",
      "weighted avg       0.78      0.73      0.74      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_lr1 = LogisticRegression(**study_lr1.best_params)\n",
    "best_model_lr1.fit(X_resampled,y_resampled)\n",
    "y_pred_lr1 = best_model_lr1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_lr1,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e719e1a3-08e9-4967-80a8-ebe1b465f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-25 20:28:52,229] A new study created in memory with name: no-name-d6b97401-499d-4c03-936f-8d67d1f57d91\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:28:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:28:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:28:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:28:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:28:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:28:56,535] Trial 0 finished with value: 0.9600408051045989 and parameters: {'n_estimators': 131, 'max_depth': 10, 'learning_rate': 0.08283539041068189, 'subsample': 0.8853156575306538, 'colsample_bytree': 0.876711338765223}. Best is trial 0 with value: 0.9600408051045989.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:28:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:28:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:28:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:03,343] Trial 1 finished with value: 0.958714445264258 and parameters: {'n_estimators': 283, 'max_depth': 15, 'learning_rate': 0.14851197174266137, 'subsample': 0.5662588941062086, 'colsample_bytree': 0.7999873913962969}. Best is trial 0 with value: 0.9600408051045989.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:07,991] Trial 2 finished with value: 0.9593727544255313 and parameters: {'n_estimators': 181, 'max_depth': 12, 'learning_rate': 0.24503347682777202, 'subsample': 0.8036167609063772, 'colsample_bytree': 0.6047465781397914}. Best is trial 0 with value: 0.9600408051045989.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:16,664] Trial 3 finished with value: 0.9582733395440324 and parameters: {'n_estimators': 465, 'max_depth': 6, 'learning_rate': 0.01311096830748043, 'subsample': 0.6260615362403243, 'colsample_bytree': 0.8009636501745523}. Best is trial 0 with value: 0.9600408051045989.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:26,757] Trial 4 finished with value: 0.9608699222128377 and parameters: {'n_estimators': 499, 'max_depth': 14, 'learning_rate': 0.17696434427945915, 'subsample': 0.6786934565883818, 'colsample_bytree': 0.5592670095609975}. Best is trial 4 with value: 0.9608699222128377.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:33,178] Trial 5 finished with value: 0.962089392956399 and parameters: {'n_estimators': 233, 'max_depth': 16, 'learning_rate': 0.12962904288911323, 'subsample': 0.6923513187802837, 'colsample_bytree': 0.6598265149539073}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:42,065] Trial 6 finished with value: 0.959170191500726 and parameters: {'n_estimators': 257, 'max_depth': 14, 'learning_rate': 0.02150009067655935, 'subsample': 0.5558298016769129, 'colsample_bytree': 0.6308886489205102}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:48,730] Trial 7 finished with value: 0.9584802358355928 and parameters: {'n_estimators': 306, 'max_depth': 15, 'learning_rate': 0.18353703986961709, 'subsample': 0.5143758097453353, 'colsample_bytree': 0.6841701077406778}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:53,403] Trial 8 finished with value: 0.9591037844265321 and parameters: {'n_estimators': 205, 'max_depth': 17, 'learning_rate': 0.26221575651663415, 'subsample': 0.5307126905093742, 'colsample_bytree': 0.9912694165576335}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:29:57,816] Trial 9 finished with value: 0.9605513747344814 and parameters: {'n_estimators': 441, 'max_depth': 3, 'learning_rate': 0.17684175608190553, 'subsample': 0.8823246912097154, 'colsample_bytree': 0.566281353901717}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:29:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:30:09,589] Trial 10 finished with value: 0.9608175396153686 and parameters: {'n_estimators': 373, 'max_depth': 20, 'learning_rate': 0.044175184111954535, 'subsample': 0.7465354724370709, 'colsample_bytree': 0.7028644805704446}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:30:19,910] Trial 11 finished with value: 0.9606303910033966 and parameters: {'n_estimators': 385, 'max_depth': 19, 'learning_rate': 0.08737821466449544, 'subsample': 0.691565080990725, 'colsample_bytree': 0.5165143580180218}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:30:28,707] Trial 12 finished with value: 0.960813406207976 and parameters: {'n_estimators': 354, 'max_depth': 11, 'learning_rate': 0.09778063730539605, 'subsample': 0.6642851894532855, 'colsample_bytree': 0.5068577987259384}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:30:39,919] Trial 13 finished with value: 0.9619951482425009 and parameters: {'n_estimators': 499, 'max_depth': 8, 'learning_rate': 0.05269787745343298, 'subsample': 0.9758831748255746, 'colsample_bytree': 0.6715699983896787}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:30:45,373] Trial 14 finished with value: 0.9599169944049845 and parameters: {'n_estimators': 216, 'max_depth': 8, 'learning_rate': 0.044487659067261216, 'subsample': 0.9995683596596627, 'colsample_bytree': 0.7204528119195516}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:30:47,635] Trial 15 finished with value: 0.9525122366530194 and parameters: {'n_estimators': 108, 'max_depth': 6, 'learning_rate': 0.025432649326617165, 'subsample': 0.981199633925122, 'colsample_bytree': 0.6454020671044397}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:30:55,937] Trial 16 finished with value: 0.960760264508543 and parameters: {'n_estimators': 319, 'max_depth': 9, 'learning_rate': 0.06077593189725636, 'subsample': 0.8064009491854932, 'colsample_bytree': 0.7804487761907153}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:30:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:31:06,224] Trial 17 finished with value: 0.9599289199357586 and parameters: {'n_estimators': 256, 'max_depth': 18, 'learning_rate': 0.030532170736823596, 'subsample': 0.8945438674193351, 'colsample_bytree': 0.6626765522331788}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:31:10,624] Trial 18 finished with value: 0.9603160684243723 and parameters: {'n_estimators': 427, 'max_depth': 3, 'learning_rate': 0.11904848552632, 'subsample': 0.755026763300621, 'colsample_bytree': 0.8507844482744875}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:31:14,417] Trial 19 finished with value: 0.9585219710026169 and parameters: {'n_estimators': 167, 'max_depth': 7, 'learning_rate': 0.0591559502450382, 'subsample': 0.9500667395254951, 'colsample_bytree': 0.740352837301428}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:31:26,353] Trial 20 finished with value: 0.957700886711588 and parameters: {'n_estimators': 338, 'max_depth': 13, 'learning_rate': 0.010012476887514036, 'subsample': 0.6073970429035704, 'colsample_bytree': 0.5940288542289784}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:31:37,129] Trial 21 finished with value: 0.959480104112501 and parameters: {'n_estimators': 495, 'max_depth': 16, 'learning_rate': 0.1397297344210453, 'subsample': 0.7111017312307868, 'colsample_bytree': 0.546766863341634}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:31:46,703] Trial 22 finished with value: 0.9612513039789183 and parameters: {'n_estimators': 500, 'max_depth': 12, 'learning_rate': 0.2066250217453661, 'subsample': 0.6475963334076242, 'colsample_bytree': 0.5941656507715389}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:31:54,189] Trial 23 finished with value: 0.958456463536573 and parameters: {'n_estimators': 407, 'max_depth': 11, 'learning_rate': 0.29128592479335375, 'subsample': 0.605705462667702, 'colsample_bytree': 0.6232282710408573}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:31:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:32:01,274] Trial 24 finished with value: 0.9607723883074311 and parameters: {'n_estimators': 471, 'max_depth': 5, 'learning_rate': 0.06991944501796195, 'subsample': 0.8197483775990756, 'colsample_bytree': 0.6687021421635502}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:32:10,894] Trial 25 finished with value: 0.9602843195575916 and parameters: {'n_estimators': 451, 'max_depth': 9, 'learning_rate': 0.11249871111956916, 'subsample': 0.6456998693411522, 'colsample_bytree': 0.5889269581926752}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:32:22,923] Trial 26 finished with value: 0.9605988463500976 and parameters: {'n_estimators': 404, 'max_depth': 12, 'learning_rate': 0.04163960417626816, 'subsample': 0.7282149394446344, 'colsample_bytree': 0.7587510794811114}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:32:28,585] Trial 27 finished with value: 0.959361848805805 and parameters: {'n_estimators': 226, 'max_depth': 17, 'learning_rate': 0.21463916040191305, 'subsample': 0.7720837286197435, 'colsample_bytree': 0.6976142845337636}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:32:35,318] Trial 28 finished with value: 0.9585324751576035 and parameters: {'n_estimators': 283, 'max_depth': 10, 'learning_rate': 0.12455519980124308, 'subsample': 0.5838115932084063, 'colsample_bytree': 0.646835138730247}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:32:46,098] Trial 29 finished with value: 0.9592674427300913 and parameters: {'n_estimators': 420, 'max_depth': 10, 'learning_rate': 0.07512448806561707, 'subsample': 0.9032901682705875, 'colsample_bytree': 0.9085312960742904}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:32:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:33:01,499] Trial 30 finished with value: 0.9599209581203614 and parameters: {'n_estimators': 482, 'max_depth': 13, 'learning_rate': 0.03231228544621089, 'subsample': 0.8556708840813676, 'colsample_bytree': 0.7348352226180072}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:33:11,381] Trial 31 finished with value: 0.9612772588477754 and parameters: {'n_estimators': 493, 'max_depth': 14, 'learning_rate': 0.19029746802855854, 'subsample': 0.6884026024809736, 'colsample_bytree': 0.5568097253144384}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:33:20,448] Trial 32 finished with value: 0.9586309752883532 and parameters: {'n_estimators': 455, 'max_depth': 15, 'learning_rate': 0.21422931217551777, 'subsample': 0.7092089593933824, 'colsample_bytree': 0.5491817137892597}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:33:25,190] Trial 33 finished with value: 0.9587757853624141 and parameters: {'n_estimators': 161, 'max_depth': 13, 'learning_rate': 0.1555586230411989, 'subsample': 0.651868972192703, 'colsample_bytree': 0.6046730642315372}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:33:34,758] Trial 34 finished with value: 0.961018372855515 and parameters: {'n_estimators': 478, 'max_depth': 16, 'learning_rate': 0.22701252491156013, 'subsample': 0.7829794451219083, 'colsample_bytree': 0.531859198586885}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:33:45,322] Trial 35 finished with value: 0.9598592758991756 and parameters: {'n_estimators': 444, 'max_depth': 12, 'learning_rate': 0.09887729060914517, 'subsample': 0.6245263851088018, 'colsample_bytree': 0.5848551108919688}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:33:55,869] Trial 36 finished with value: 0.9619909815289398 and parameters: {'n_estimators': 493, 'max_depth': 14, 'learning_rate': 0.14978728045422832, 'subsample': 0.6958241399997993, 'colsample_bytree': 0.6237393985467404}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:33:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:02,713] Trial 37 finished with value: 0.9590595997976307 and parameters: {'n_estimators': 261, 'max_depth': 14, 'learning_rate': 0.15334668992659592, 'subsample': 0.7015931338390107, 'colsample_bytree': 0.6181598153121978}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:17,039] Trial 38 finished with value: 0.9609172197000493 and parameters: {'n_estimators': 477, 'max_depth': 16, 'learning_rate': 0.051187402912883644, 'subsample': 0.8402387458137607, 'colsample_bytree': 0.6755033110918643}. Best is trial 5 with value: 0.962089392956399.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:21,861] Trial 39 finished with value: 0.962726339783049 and parameters: {'n_estimators': 192, 'max_depth': 14, 'learning_rate': 0.29082298587954764, 'subsample': 0.7350709182078545, 'colsample_bytree': 0.8178209009521108}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:28,591] Trial 40 finished with value: 0.9558447919924229 and parameters: {'n_estimators': 150, 'max_depth': 18, 'learning_rate': 0.01816446603897848, 'subsample': 0.7301615447369822, 'colsample_bytree': 0.8285880295229717}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:33,470] Trial 41 finished with value: 0.9592849200002987 and parameters: {'n_estimators': 191, 'max_depth': 14, 'learning_rate': 0.27883550302085114, 'subsample': 0.7827139288006233, 'colsample_bytree': 0.9300846495071864}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:37,553] Trial 42 finished with value: 0.9592214287814198 and parameters: {'n_estimators': 139, 'max_depth': 14, 'learning_rate': 0.2445617466505873, 'subsample': 0.680396776213449, 'colsample_bytree': 0.816095533573756}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:44,014] Trial 43 finished with value: 0.9605935235796389 and parameters: {'n_estimators': 247, 'max_depth': 15, 'learning_rate': 0.1814202671579488, 'subsample': 0.7429011414363319, 'colsample_bytree': 0.7744312841670392}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:48,579] Trial 44 finished with value: 0.9588608322524689 and parameters: {'n_estimators': 192, 'max_depth': 17, 'learning_rate': 0.29924573656715614, 'subsample': 0.6736835273329046, 'colsample_bytree': 0.704807529660054}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:34:55,152] Trial 45 finished with value: 0.9607254091240216 and parameters: {'n_estimators': 234, 'max_depth': 15, 'learning_rate': 0.13485097210374153, 'subsample': 0.7121033002112457, 'colsample_bytree': 0.6421948313657343}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:34:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:35:02,408] Trial 46 finished with value: 0.9602662877936844 and parameters: {'n_estimators': 291, 'max_depth': 13, 'learning_rate': 0.17493099383120972, 'subsample': 0.767523795346878, 'colsample_bytree': 0.5704925158557892}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:35:07,505] Trial 47 finished with value: 0.9583352950298109 and parameters: {'n_estimators': 114, 'max_depth': 16, 'learning_rate': 0.0813066239325321, 'subsample': 0.9413523108851605, 'colsample_bytree': 0.8918611383635215}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:35:13,363] Trial 48 finished with value: 0.9598758907974794 and parameters: {'n_estimators': 206, 'max_depth': 18, 'learning_rate': 0.10288779156245488, 'subsample': 0.5648443734184609, 'colsample_bytree': 0.8578440973689946}. Best is trial 39 with value: 0.962726339783049.\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
      "C:\\Users\\mohan\\AppData\\Local\\Temp\\ipykernel_3524\\2855104916.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:13] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:14] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\mohan\\AppData\\Roaming\\Python\\Python313\\site-packages\\xgboost\\training.py:183: UserWarning: [20:35:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-06-25 20:35:20,911] Trial 49 finished with value: 0.9597634230886293 and parameters: {'n_estimators': 385, 'max_depth': 11, 'learning_rate': 0.24615503951471124, 'subsample': 0.6875952381379304, 'colsample_bytree': 0.6897290797347764}. Best is trial 39 with value: 0.962726339783049.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Best Parameters {'n_estimators': 192, 'max_depth': 14, 'learning_rate': 0.29082298587954764, 'subsample': 0.7350709182078545, 'colsample_bytree': 0.8178209009521108}\n"
     ]
    }
   ],
   "source": [
    "#XGBoost classifier\n",
    "\n",
    "def objective_xgb1(trial):\n",
    "    params = {\n",
    "        'n_estimators':trial.suggest_int('n_estimators',100,500),\n",
    "        'max_depth':trial.suggest_int('max_depth',3,20),\n",
    "        'learning_rate':trial.suggest_loguniform('learning_rate',0.01,0.3),\n",
    "        'subsample':trial.suggest_uniform('subsample',0.5,1),\n",
    "        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.5,1)\n",
    "    }\n",
    "    model1=XGBClassifier(**params,use_label_encoder=False,eval_metric='logloss',random_state=42)\n",
    "    return cross_val_score(model1,X_resampled,y_resampled,cv=5,scoring='f1').mean()\n",
    "\n",
    "study_xgb1 = optuna.create_study(direction='maximize')\n",
    "study_xgb1.optimize(objective_xgb1,n_trials=50) \n",
    "print(\"XGBoost Classifier Best Parameters\",study_xgb1.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "87cf360b-bb01-4fc8-bad9-240d94dadbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1033\n",
      "           1       0.54      0.67      0.60       374\n",
      "\n",
      "    accuracy                           0.76      1407\n",
      "   macro avg       0.70      0.73      0.71      1407\n",
      "weighted avg       0.78      0.76      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_xgb1 = XGBClassifier(**study_xgb1.best_params)\n",
    "best_model_xgb1.fit(X_resampled,y_resampled)\n",
    "y_pred_xgb1 = best_model_xgb1.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_xgb1,labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb5c49ce-7cf0-41da-b652-8f43c57bd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = []\n",
    "#random forest\n",
    "best_model_rf1 = RandomForestClassifier(**study_rf1.best_params)\n",
    "best_model_rf1.fit(X_resampled,y_resampled)\n",
    "y_pred_rf1 = best_model_rf1.predict(X_test)\n",
    "f1_rf1 = f1_score(y_test,y_pred_rf1,average='weighted')\n",
    "\n",
    "result1.append({\n",
    "    'model':'Random Forest','f1_score':f1_rf1,'params':study_rf1.best_params\n",
    "})\n",
    "\n",
    "#decision tree\n",
    "best_model_dt1 = DecisionTreeClassifier(**study_dt1.best_params)\n",
    "best_model_dt1.fit(X_resampled,y_resampled)\n",
    "y_pred_dt1 = best_model_dt1.predict(X_test)\n",
    "f1_dt1 = f1_score(y_test,y_pred_dt1,average='weighted')\n",
    "\n",
    "result1.append({\n",
    "    'model':'Decision Tree','f1_score':f1_dt1,'params':study_dt.best_params\n",
    "})\n",
    "\n",
    "#Logistic Regression\n",
    "\n",
    "best_model_lr1 = LogisticRegression(**study_lr1.best_params)\n",
    "best_model_lr1.fit(X_resampled,y_resampled)\n",
    "y_pred_lr1 = best_model_lr1.predict(X_test)\n",
    "f1_lr1 = f1_score(y_test,y_pred_lr1,average='weighted')\n",
    "\n",
    "result1.append({\n",
    "    'model':'LogisticRegression','f1_score':f1_lr1,'params':study_lr1.best_params\n",
    "})\n",
    "\n",
    "\n",
    "#XGBoost\n",
    "best_model_xgb1 = XGBClassifier(**study_xgb1.best_params)\n",
    "best_model_xgb1.fit(X_resampled,y_resampled)\n",
    "y_pred_xgb1 = best_model_xgb1.predict(X_test)\n",
    "f1_xgb1 = f1_score(y_test,y_pred_xgb1,average='weighted')\n",
    "\n",
    "result1.append({\n",
    "    'model':'XGBoost','f1_score':f1_xgb1,'params':study_xgb1.best_params\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7f017396-8170-47d8-b15b-d72b6edf2b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                model  f1_score  \\\n",
      "0       Random Forest  0.771284   \n",
      "3             XGBoost  0.766080   \n",
      "1       Decision Tree  0.763016   \n",
      "2  LogisticRegression  0.740665   \n",
      "\n",
      "                                              params  \n",
      "0  {'n_estimators': 383, 'max_depth': 14, 'min_sa...  \n",
      "3  {'n_estimators': 192, 'max_depth': 14, 'learni...  \n",
      "1  {'max_depth': 6, 'min_samples_split': 14, 'min...  \n",
      "2  {'C': 0.4960411096906256, 'penalty': 'l2', 'so...  \n"
     ]
    }
   ],
   "source": [
    "results_df1 = pd.DataFrame(result1)\n",
    "results_df1=results_df1.sort_values(by='f1_score',ascending=False)\n",
    "print(results_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "806aae2b-738d-485b-9577-7b40511b9316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_model_rf1,open('final_churn.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5efff97-f8af-456b-bef7-638a79b29617",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = pickle.load(open('final_churn.sav','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f890a6dc-16db-4450-9656-1d09701e44f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f985e-81af-4e0c-972f-893f608cade6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee5cca-ef37-4665-992c-2c13c692f59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
